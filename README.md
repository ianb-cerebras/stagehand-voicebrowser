# Stagehand Voice Browser ğŸš€ğŸ—£ï¸

Voice-controlled, AI-powered web automation built with **Stagehand**, **Playwright**, and local **Whisper (faster-whisper)** speech-to-text, with Cerebras LLM calls for lightweight intent classification.

---

## âœ¨ Key Features

1. **Natural-language browser control** â€“ Say commands like â€œ*Click the sign-in button*â€ and Stagehand executes them.
2. **Push-to-Talk** â€“ Hold the **`m`** key to record audio; release to send.
3. **Local STT** â€“ Runs Whisper on-device (no external STT bills, works offline).
4. **Scroll intent classifier** â€“ Cerebras Llama-4 model responds with `1 | 2 | 3` so we can intercept â€œscroll up / downâ€ instantly.
5. **Structured LLM Output** â€“ Uses Cerebras *structured output* (`response_format: json_schema`) for guaranteed JSON replies.
6. **Cross-platform** â€“ macOS / Linux (requires FFmpeg and Python 3.11).


---

## ğŸ”§ Requirements

| Tool | Version | Notes |
|------|---------|-------|
| Node.js | â‰¥ 18 | Stagehand & Playwright |
| Python  | 3.11 | faster-whisper agent |
| FFmpeg  | any  | Audio device capture |

> macOS users: `brew install ffmpeg`.

---

## ğŸ—ï¸  Setup

```bash
# 1. Clone & install JS deps
npm install

# 2. Python venv + deps
python3.11 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

Create a `.env`:

```bash
CEREBRAS_API_KEY=your_key_here  # required
```

---

## â–¶ï¸  Running

```bash
npm start
```

1. A headless browser launches and navigates to Google.
2. Terminal prints:
   ```
   ğŸ¤ Press 'm' to toggle microphone recording
   ```
3. **Hold `m`**, speak, **release**.
4. Watch the command run or scroll.

---

## ğŸ™ï¸  Command Cheatsheet

| Voice phrase | Result |
|--------------|--------|
| â€œscroll downâ€ | page scrolls 50 vh down |
| â€œscroll upâ€ | page scrolls 50 vh up |
| anything else | forwarded to Stagehand `page.act` |
| â€œexit / quit / stopâ€ | shuts everything down |

---

## âš™ï¸  Environment Variables

* `CEREBRAS_API_KEY` â€“ **required** for the classifier.
